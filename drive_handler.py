# drive_handler.py (multi-PDF ë³‘í•© ì§€ì› ë²„ì „)

import datetime
import fitz  # PyMuPDF
import io
import unicodedata
from googleapiclient.discovery import build
from google.oauth2 import service_account
from googleapiclient.http import MediaIoBaseDownload

# 1. Google Drive API ì¸ì¦
def get_drive_service_from_secrets(secret_dict):
    creds = service_account.Credentials.from_service_account_info(secret_dict)
    return build("drive", "v3", credentials=creds)

# 2. ì£¼ì°¨ ê³„ì‚°
def get_current_week(start_date: datetime.date, today: datetime.date) -> int:
    return ((today - start_date).days // 7) + 1

# 3. ë¬¸ìžì—´ ì •ê·œí™”
def normalize(text):
    return unicodedata.normalize('NFKC', text).replace(" ", "").lower()

# 4. ì£¼ì°¨ë³„ PDF í…ìŠ¤íŠ¸ ë³‘í•© + ë§ˆì§€ë§‰ PDF ë°”ì´ë„ˆë¦¬ ë°˜í™˜
def get_weekly_files_with_binary(service, folder_id, week_num):
    def fetch_all_files(week_keyword):
        query = f"'{folder_id}' in parents and trashed = false and mimeType = 'application/pdf'"
        results = service.files().list(q=query, fields="files(id, name, createdTime)").execute()
        files = results.get("files", [])

        matched_files = [f for f in files if normalize(week_keyword) in normalize(f["name"])]
        matched_files.sort(key=lambda f: f["createdTime"])  # ì˜¤ëž˜ëœ ìˆœì„œ â†’ ë§ˆì§€ë§‰ íŒŒì¼ì€ ìµœì‹ 

        print(f"ðŸ“‚ {week_keyword} ê´€ë ¨ PDF ìˆ˜: {len(matched_files)}")
        return matched_files

    def download_and_extract_text(file_id):
        try:
            request = service.files().get_media(fileId=file_id)
            fh = io.BytesIO()
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                _, done = downloader.next_chunk()
            fh.seek(0)
            doc = fitz.open("pdf", fh.read())
            return "\n".join([page.get_text() for page in doc]), fh
        except Exception as e:
            print(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨ (ID: {file_id}) - {e}")
            return "", None

    # ì´ë²ˆ ì£¼ì°¨
    this_week_keyword = f"{week_num}ì£¼ì°¨"
    this_files = fetch_all_files(this_week_keyword)

    this_text_merged = ""
    this_week_bytes = None

    for idx, file in enumerate(this_files):
        text, file_bytes = download_and_extract_text(file["id"])
        this_text_merged += text + "\n"
        if idx == len(this_files) - 1:  # ê°€ìž¥ ë§ˆì§€ë§‰ íŒŒì¼ì€ binaryë¡œ ì €ìž¥
            this_week_bytes = file_bytes

    # ì§€ë‚œ ì£¼ì°¨ (ë‹¨ì¼ PDFë§Œ ì²˜ë¦¬)
    last_text = None
    if week_num > 1:
        last_week_keyword = f"{week_num - 1}ì£¼ì°¨"
        last_files = fetch_all_files(last_week_keyword)
        if last_files:
            last_text, _ = download_and_extract_text(last_files[-1]["id"])

    return last_text, this_text_merged.strip(), this_week_bytes
